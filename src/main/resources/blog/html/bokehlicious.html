
  <!doctype html>
    <html lang="en">
      <head>
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <title>Bokehlicious Selfies</title>
        <link rel="preconnect" href="https://fonts.gstatic.com">
      </head>
      <body>
        
      <header class="container-fluid">
        <nav>
          <ul>
            <li><strong>Rahul Ravikumar's Blog</strong></li>
          </ul>
          <ul>
            <li><a href="/blog/toc.html" class="contrast">More Articles</a></li>
          </ul>
        </nav>
      </header>
      <main class="container">
        <p>Mar 27 2020, Friday</p>
<h2 id="bokehlicious-selfies">Bokehlicious Selfies</h2>
<p>I signed up for the excellent <a href="https://course.fast.ai/">fastai MOOC</a> recently, and one of the project ideas I had was the idea of adding <a href="https://en.wikipedia.org/wiki/Bokeh"> <code class="prettyprint">bokehs</code></a> to selfies using Deep learning. Most phones have a not so great selfie (front-side) camera and therefore this idea has some merits.</p>
<p>Google Photos does something like this and it's quite magical <em>when it works</em>. So i wanted to experiment with a simple pipeline which could be used to add a <code class="prettyprint">bokeh</code> to a selfie that did not have one. </p>
<h2 id="breaking-down-the-problem">Breaking down the problem</h2>
<p>One idea I had was to be able to use image-segmentation to identify and build a segmentation <code class="prettyprint">mask</code> around the person in the image. For this I used the excellent <code class="prettyprint">torchvision.models.detection.maskrcnn_resnet50_fpn</code> pretrainted model.  This model has been trained with the <a href="http://cocodataset.org/#home">COCO dataset</a>, and therefore is pretty great out of the box for the given use-case.</p>
<p>Once we have a segmentation <code class="prettyprint">mask</code> of the person in the image; we could then use that to split the image into a <code class="prettyprint">foreground</code> or a <code class="prettyprint">subject</code>, and the rest of it would be <code class="prettyprint">background</code>. I could then use image convolution to create a <code class="prettyprint">bokeh</code> effect on the <code class="prettyprint">background</code> image and merge it with the <code class="prettyprint">subject</code> to give it a nice pop.</p>
<p>One key thing to remember is that the <code class="prettyprint">merged</code> image is <em>only</em> as good as the segmentation <code class="prettyprint">mask</code>, but given I am restricting the input image type to a portrait <code class="prettyprint">selfie</code> this works <em>most</em> of the time.</p>
<h2 id="lets-write-some-code">Let's write some code</h2>
<h3 id="the-bokeh-effect">The Bokeh Effect</h3>
<p>I read this <a href="https://www.scratchapixel.com/lessons/digital-imaging/simple-image-manipulations/bookeh-effect">incredible article</a> on how to simulate a <code class="prettyprint">bokeh</code> effect.  I then adapted the idea and wrote a quick <code class="prettyprint">Python</code> implementation using some helpers from <code class="prettyprint">OpenCV</code>. </p>
<p>Let's start with our imports.</p>
<pre class="prettyprint linenums"><code class="python language-python">import cv2
import math
import numpy as np
import matplotlib.pyplot as plt

plt.rcParams["figure.figsize"]= (10,10)
np.set_printoptions(precision=3)</code></pre>
<p>We need to build a convolution <code class="prettyprint">kernel</code> which can produce a <code class="prettyprint">bokeh</code> effect. The idea here is to take a <code class="prettyprint">gaussian</code> kernel with a large standard-deviation and multiply it with a simple binary mask to emphasize the effect. </p>
<pre class="prettyprint linenums"><code class="python language-python">triangle = np.array([
    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
    [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0],
    [0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0],
    [0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0],
    [0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0],
    [0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0],
    [0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0],
    [0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0],
    [0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0],
    [0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0],
    [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],
], dtype='float')

mask = triangle
kernel = cv2.getGaussianKernel(11, 5.)
kernel = kernel * kernel.transpose() * mask # Is the 2D filter
kernel = kernel / np.sum(kernel)
print(kernel)</code></pre>
<p>This produces something like:</p>
<pre class="prettyprint linenums"><code>[[0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.016 0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.018 0.018 0.018 0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.02  0.02  0.02  0.    0.    0.    0.   ]
 [0.    0.    0.    0.02  0.021 0.021 0.021 0.02  0.    0.    0.   ]
 [0.    0.    0.    0.02  0.021 0.022 0.021 0.02  0.    0.    0.   ]
 [0.    0.    0.018 0.02  0.021 0.021 0.021 0.02  0.018 0.    0.   ]
 [0.    0.    0.017 0.019 0.02  0.02  0.02  0.019 0.017 0.    0.   ]
 [0.    0.013 0.015 0.017 0.018 0.018 0.018 0.017 0.015 0.013 0.   ]
 [0.    0.012 0.013 0.015 0.016 0.016 0.016 0.015 0.013 0.012 0.   ]
 [0.008 0.01  0.011 0.012 0.013 0.013 0.013 0.012 0.011 0.01  0.008]]</code></pre>
<p>Let's try the <code class="prettyprint">kernel</code>. First, lets load the input image:</p>
<pre class="prettyprint linenums"><code class="python language-python"># Credit for the image: https://fixthephoto.com/self-portrait-ideas.html
image = cv2.imread('images/selfie-1.jpg')
image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
plt.imshow(image)</code></pre>
<p><img class="card mdc-card mdc-card__media mdc-card__media--16-9"  src="/assets/images/selfie_original.png" alt="Original" /></p>
<p>Now, let's define the actual <code class="prettyprint">bokeh</code> function that applies the kernel.</p>
<pre class="prettyprint linenums"><code class="python language-python">def bokeh(image):
    r,g,b = cv2.split(image)

    r = r / 255.
    g = g / 255.
    b = b / 255.

    r = np.where(r &gt; 0.9, r * 2, r)
    g = np.where(g &gt; 0.9, g * 2, g)
    b = np.where(b &gt; 0.9, b * 2, b)

    fr = cv2.filter2D(r, -1, kernel)
    fg = cv2.filter2D(g, -1, kernel)
    fb = cv2.filter2D(b, -1, kernel)

    fr = np.where(fr &gt; 1., 1., fr)
    fg = np.where(fg &gt; 1., 1., fg)
    fb = np.where(fb &gt; 1., 1., fb)

    result = cv2.merge((fr, fg, fb))
    return result

result = bokeh(image)
plt.imshow(result)</code></pre>
<p><img class="card mdc-card mdc-card__media mdc-card__media--16-9"  src="/assets/images/selfie_bokeh_full.png" alt="Full Bokeh" /></p>
<p>We now have a method that can generate a <code class="prettyprint">bokeh</code> effect for a given image.</p>
<h3 id="image-segmentation">Image Segmentation</h3>
<p>We now need to use the <code class="prettyprint">torchvision.models.detection.maskrcnn_resnet50_fpn</code> pretrained model to segment the above image to split into <code class="prettyprint">foreground</code> &amp; <code class="prettyprint">background</code>. Let's do that.</p>
<pre class="prettyprint linenums"><code class="python language-python">import torch
import torchvision

model = torchvision.models.detection.maskrcnn_resnet50_fpn(pretrained=True)
model.eval()

image = cv2.imread('images/selfie-1.jpg')
image = cv2.cvtColor(original, cv2.COLOR_BGR2RGB) # OpenCV uses BGR by default

image = image / 255. # Normalize image
channels_first = np.moveaxis(image, 2, 0) # Channels first

# The pre-trained model expects a float32 type
channels_first = torch.from_numpy(channels_first).float()

prediction = model([channels_first])[0]
scores = prediction['scores'].detach().numpy()
masks = prediction['masks'].detach().numpy()
mask = masks[0][0]  
plt.imshow(masks[0][0])</code></pre>
<p>This produces a segmentation-mask which looks like:</p>
<p><img class="card mdc-card mdc-card__media mdc-card__media--16-9"  src="/assets/images/selfie_segmentation_mask.png" alt="Segmentation Mask" /></p>
<h3 id="splitting--merging">Splitting &amp; Merging</h3>
<p>Now that we have a segmentation-mask we can split the image into <code class="prettyprint">foreground</code> and <code class="prettyprint">background</code> like so:</p>
<pre class="prettyprint linenums"><code class="python language-python">inverted = np.abs(1. - mask)

r,g,b = cv2.split(image)
mr = r * mask
mg = g * mask
mb = b * mask
subject = cv2.merge((mr, mg, mb))

ir = r * inverted
ig = g * inverted
ib = b * inverted
background = cv2.merge((ir, ig, ib))

subject = np.asarray(subject * 255., dtype='uint8')
plt.imshow(subject)</code></pre>
<p><img class="card mdc-card mdc-card__media mdc-card__media--16-9"  src="/assets/images/selfie_foreground.png" alt="Foreground" /></p>
<p>Let's now apply the <code class="prettyprint">bokeh</code> effect on the <code class="prettyprint">background</code> image and them merge both images.</p>
<pre class="prettyprint linenums"><code class="python language-python">background_bokeh = bokeh(np.asarray(background * 255, dtype='uint8'))
background_bokeh = np.asarray(background_bokeh * 255, dtype='uint8')
combined = cv2.addWeighted(subject, 1., background_bokeh, 1., 0)
plt.imshow(combined)</code></pre>
<p><img class="card mdc-card mdc-card__media mdc-card__media--16-9"  src="/assets/images/selfie_bokeh_pop.png" alt="Selfie with Bokeh" /></p>
<h2 id="conclusion">Conclusion</h2>
<p>Deep learning is magical for applications like these. I hope you enjoyed reading the article.</p>
        <section class="footer">
          <p>
          Rahul Ravikumar &nbsp;
            <a rel="me" href="https://github.com/tikurahul">GitHub</a> &nbsp; | &nbsp;
            <a rel="me" href="https://rahulrav.svbtle.com/">Svbtle</a> &nbsp; | &nbsp;
            <a rel="me" href="https://twitter.com/tikurahul">Twitter</a> &nbsp; | &nbsp;
            <a rel="me" href="https://www.linkedin.com/in/rahulrav/">LinkedIn</a> &nbsp; | &nbsp;
            <a rel="me" href="https://androiddev.social/@rahulrav">AndroidDev Mastodon</a>
          </p>
        </section>
      </main>
    </div>
  
        <link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Roboto&family=Zilla+Slab&display=swap">
        <link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=JetBrains+Mono&display=swap">
        <link rel="stylesheet" href="/assets/highlight/styles/dracula.css">
        <link rel="stylesheet" href="/assets/core/page.css">
        <script type="text/javascript" src="/assets/core/page.js"></script>
        <script type="text/javascript" src="/assets/highlight/highlight.pack.js"></script>
        <script type="text/javascript">
          // Highlight code snippets
          document.addEventListener('DOMContentLoaded', (event) => {
            document.querySelectorAll('pre code').forEach((block) => {
              hljs.highlightBlock(block);
            });
          });
        </script>
      </body>
    </html>
  